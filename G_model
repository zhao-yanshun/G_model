# coding: utf-8

# In[1]:


import functools
from functools import partial, reduce
import argparse
import os
import matplotlib.pyplot as plt
from matplotlib.pyplot import imshow
import scipy.io
import scipy.misc
import numpy as np
import pandas as pd
import PIL
import tensorflow as tf
from keras import backend as K
from keras.layers import Input, Lambda, Conv2D, MaxPooling2D, BatchNormalization, LeakyReLU, Add
from keras.layers.merge import concatenate
from keras.models import load_model, Model
from keras.regularizers import l2

from yad2k.models.keras_yolo import space_to_depth_x2, space_to_depth_x2_output_shape, preprocess_true_boxes
from yad2k.models.keras_yolo import yolo_head,yolo_boxes_to_corners,preprocess_true_boxes,yolo_loss,yolo_eval
from data_process import load_data,process_data
from yad2k.utils.draw_boxes import draw_boxes

import yolo_utils

get_ipython().run_line_magic('matplotlib', 'inline')


# In[2]:


def get_detector_mask(boxes, anchors):
    '''
    Precompute detectors_mask and matching_true_boxes for training.
    Detectors mask is 1 for each spatial position in the final conv layer and
    anchor that should be active for the given boxes and 0 otherwise.
    Matching true boxes gives the regression targets for the ground truth box
    that caused a detector to be active or 0 otherwise.
    '''
    detectors_mask = [0 for i in range(len(boxes))]
    matching_true_boxes = [0 for i in range(len(boxes))]
    for i, box in enumerate(boxes):
        detectors_mask[i], matching_true_boxes[i] = preprocess_true_boxes(box, anchors, [416, 416])
        

    return np.array(detectors_mask), np.array(matching_true_boxes)


# In[3]:


def compose(*funcs):
    """Compose arbitrarily many functions, evaluated left to right.

    Reference: https://mathieularose.com/function-composition-in-python/
    """
    # return lambda x: reduce(lambda v, f: f(v), funcs, x)
    if funcs:
        return reduce(lambda f, g: lambda *a, **kw: g(f(*a, **kw)), funcs)
    else:
        raise ValueError('Composition of empty sequence not supported.')


# In[4]:


def transpose_h(x):
    return tf.transpose(x,[0,3,2,1])

def transpose_w(x):
    return tf.transpose(x,[0,1,3,2])

def transpose_c(x):
    return tf.transpose(x,[0,3,1,2])


# In[5]:


def global_conv(X,bottleneck_filters,outer_filters,l):
    X = Lambda(transpose_w,name='transpose_w'+l)(X)
    X = Conv2D(bottleneck_filters, (1, 1), strides = (1, 1), padding = 'same',
               kernel_initializer='he_normal',kernel_regularizer =  l2(5e-4),
               name = 'conv_w'+l)(X)
    
    X = Lambda(transpose_h,name='transpose_h'+l)(X)
    X = Conv2D(bottleneck_filters, (1, 1), strides = (1, 1), padding = 'same',
               kernel_initializer='he_normal',kernel_regularizer =  l2(5e-4),
               name = 'conv_h'+l)(X)
    
    X = Lambda(transpose_c,name='transpose_c'+l)(X)
    X = Conv2D(outer_filters, (1, 1), strides = (1, 1), padding = 'same',
               kernel_initializer='he_normal',kernel_regularizer =  l2(5e-4),
               name = 'conv_c'+l)(X)
    X = BatchNormalization(name = 'bn'+l,axis=-1)(X)
    
    return X


# In[6]:


# Partial wrapper for Convolution2D with static default argument.
_DarknetConv2D = partial(Conv2D, padding='same')

@functools.wraps(Conv2D)
def DarknetConv2D(*args, **kwargs):
    """Wrapper to set Darknet weight regularizer for Convolution2D."""
    darknet_conv_kwargs = {'kernel_regularizer': l2(5e-4)}
    darknet_conv_kwargs.update(kwargs)
    return _DarknetConv2D(*args, **darknet_conv_kwargs)


def DarknetConv2D_BN(*args, **kwargs):
    """Darknet Convolution2D followed by BatchNormalization."""
    no_bias_kwargs = {'use_bias': False}
    no_bias_kwargs.update(kwargs)
    return compose(
        DarknetConv2D(*args, **no_bias_kwargs),
        BatchNormalization())


def DarknetConv2D_BN_Leaky(*args, **kwargs):
    """Darknet Convolution2D followed by BatchNormalization and LeakyReLU."""
    no_bias_kwargs = {'use_bias': False}
    no_bias_kwargs.update(kwargs)
    return compose(
        DarknetConv2D(*args, **no_bias_kwargs),
        BatchNormalization(),
        LeakyReLU(alpha=0.1))


def bottleneck_block(outer_filters, bottleneck_filters):
    """Bottleneck block of 3x3, 1x1, 3x3 convolutions."""
    return compose(
        DarknetConv2D_BN_Leaky(outer_filters, (3, 3)),
        DarknetConv2D_BN_Leaky(bottleneck_filters, (1, 1)),
        DarknetConv2D_BN(outer_filters, (3, 3)))


def bottleneck_x2_block(outer_filters, bottleneck_filters):
    """Bottleneck block of 3x3, 1x1, 3x3, 1x1, 3x3 convolutions."""
    return compose(
        bottleneck_block(outer_filters, bottleneck_filters),
        LeakyReLU(alpha=0.1),
        DarknetConv2D_BN_Leaky(bottleneck_filters, (1, 1)),
        DarknetConv2D_BN_Leaky(outer_filters, (3, 3)))


# In[7]:


def Global_Yolo(X_input, num_anchors, num_classes):
   
    X1 = DarknetConv2D_BN_Leaky(32, (3, 3))(X_input)
    X1_3 = global_conv(X1, 104, 128, '1_3')
    
    X2 = compose(MaxPooling2D(),DarknetConv2D_BN_Leaky(64, (3, 3)))(X1)
    X2_4 = global_conv(X2, 52, 256, '2_4')
    
    X3 = compose(MaxPooling2D(),bottleneck_block(128, 64))(X2)
    X = Add(name='add_3')([X1_3,X3])
    X = LeakyReLU(alpha=0.1)(X)
    
    X4 = compose(MaxPooling2D(),bottleneck_block(256, 128))(X)
    X = Add(name='add_4')([X2_4,X4])
    X = LeakyReLU(alpha=0.1)(X)
    
    X5 = compose(MaxPooling2D(),bottleneck_x2_block(512, 256))(X)
    X6 = compose(
        MaxPooling2D(),bottleneck_x2_block(1024, 512),
        DarknetConv2D_BN_Leaky(1024, (3, 3)),DarknetConv2D_BN_Leaky(1024, (3, 3)))(X5)
    
    X5_6 = DarknetConv2D_BN_Leaky(64, (1, 1))(X5)
    X5_6_reshaped = Lambda(
        space_to_depth_x2,
        output_shape=space_to_depth_x2_output_shape,
        name='space_to_depth')(X5_6)
    
    X = concatenate([X5_6_reshaped, X6])
    X = DarknetConv2D_BN_Leaky(1024, (3, 3))(X)
    X = DarknetConv2D(num_anchors * (num_classes + 5), (1, 1))(X)
    
    return Model(X_input, X)


# In[8]:


def train_G_Yolo(anchors, class_names, load_pretrained=True, freeze_body=True):
    detectors_mask_shape = (13, 13, 5, 1)
    matching_boxes_shape = (13, 13, 5, 5)

    # Create model input layers.
    image_input = Input(shape=(416, 416, 3))
    boxes_input = Input(shape=(None, 5))
    detectors_mask_input = Input(shape=detectors_mask_shape)
    matching_boxes_input = Input(shape=matching_boxes_shape)
    
    G_Yolo_model = Global_Yolo(image_input,len(anchors),len(class_names))
    topless_yolo = Model(G_Yolo_model.input, G_Yolo_model.layers[-2].output)
    
    if load_pretrained:
        # Save topless yolo:
        topless_yolo.load_weights('model_data/weights.h5',by_name=True)
        
    if freeze_body:
        for layer in topless_yolo.layers:
            if ('1_3' in layer.name) or ('2_4' in layer.name):
                layer.trainable = True
            else:layer.trainable = False
                
    final_layer = Conv2D(len(anchors)*(5+len(class_names)), (1, 1), activation='linear')(topless_yolo.output)
    model_body = Model(image_input, final_layer)
    model_loss = Lambda(
                        yolo_loss,name='yolo_loss',
                        arguments={'anchors': anchors,'num_classes': len(class_names)}
                        )([model_body.output, boxes_input, detectors_mask_input, matching_boxes_input])
    
    model = Model([model_body.input, boxes_input, detectors_mask_input,matching_boxes_input], model_loss)
    
    return model_body, model


# In[9]:


class_names = yolo_utils.read_classes("model_data/train_classes.txt")
anchors = yolo_utils.read_anchors("model_data/yolo_anchors.txt")


# In[10]:


path = 'D:/datasets/PASCAL_VOC/VOCtrainval_06-Nov-2007/VOCdevkit/'
images,box_es = load_data(path+'2007_train.txt',path+'VOC2007/labels')

image_data,boxes = process_data(images,box_es)
detectors_mask, matching_true_boxes = get_detector_mask(boxes, anchors)


# In[11]:


model_body, train_model = train_G_Yolo(anchors, class_names)
train_model.compile("adam",loss={'yolo_loss': lambda y_true, y_pred: y_pred}) 
a = train_model.fit([image_data, boxes, detectors_mask, matching_true_boxes], np.zeros(len(images)),
              validation_split=0.1, batch_size=16, epochs=1)
train_model.save_weights('G_model/trained_stage1.h5')

for layer in train_model.layers:
    layer.trainable = True
train_model.compile("adam",loss={'yolo_loss': lambda y_true, y_pred: y_pred}) 


# In[14]:


b = train_model.fit([image_data, boxes, detectors_mask, matching_true_boxes], np.zeros(len(images)),
              validation_split=0.1, batch_size=8, epochs=5)
train_model.save_weights('G_model/trained_stage2.h5')



c = train_model.fit([image_data, boxes, detectors_mask, matching_true_boxes], np.zeros(len(images)),
              validation_split=0.1, batch_size=8, epochs=5)
train_model.save_weights('G_model/trained_stage3.h5')


# In[15]:


model_body.load_weights('G_model/trained_stage2.h5',by_name=True)
model_body.save('G_model/G_model.h5')
